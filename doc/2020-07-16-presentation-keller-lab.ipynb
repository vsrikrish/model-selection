{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A quick tour of model selection, combination, and regularization\n",
    "\n",
    "* Vivek Srikrishnan and James Doss-Gollin\n",
    "* Keller Group Meeting\n",
    "* Thursday 16 July 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The challenge\n",
    "\n",
    "Earth systems are:\n",
    "\n",
    "* high-dimensional multi-scale\n",
    "* nonlinear / complex\n",
    "* $\\mathcal{M}$-open (i.e., we can't write down the \"true\" model $\\approx$)\n",
    "\n",
    "When there are many candidate models, _each of which is wrong_, how should we use their collective insight to make robust and distributionally accurate predictions?\n",
    "\n",
    "> \"It's hard to make predictions, especially about the future\" -- Yogi Berra on \"equifinality\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "\n",
    "1. Model selection\n",
    "1. Regularization\n",
    "1. Model combination\n",
    "1. Next steps\n",
    "1. Further Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model selection\n",
    "\n",
    "A natural approach to dealing with a large set of candidate models is to select the model that is the \"best\". To pick the best model we'll need\n",
    "\n",
    "* some data: $(x_i, y_i)$\n",
    "* a set of candidate models $M \\in \\mathcal{M}$ where $M : x_i \\rightarrow p(y_i | x_i)$\n",
    "* some criteria for model quality: $f(M, y)$\n",
    "\n",
    "Canonical case studies and much of the theory is based on selecting which variables should be used for a linear regression, often making Gaussian approximations, but thus fare we have made no such restrictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Significance criteria\n",
    "\n",
    "Use Null Hypothesis Significance Testing (NHST) to decide whether to include a variable.\n",
    "For example, consider:\n",
    "$$\n",
    "\\begin{align}\n",
    "M_1: y_i &\\sim \\mathcal{N} \\left( \\alpha_0 + \\alpha_1 x_i , \\sigma_1^2 \\right) \\\\\n",
    "M_2: y_i &\\sim \\mathcal{N} \\left( \\beta_0 + \\beta_1 x_i + \\beta_2 t_i, \\sigma_2 ^2 \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "One could:\n",
    "\n",
    "1. Form a null hypothesis: $\\beta_2 = 0$\n",
    "1. Test statistics $\\Rightarrow$ $p$-value\n",
    "1. If $p < \\alpha$ then use $M_2$ else use $M_1$\n",
    "\n",
    "Problems:\n",
    "\n",
    "* multiple comparisons (Gelman & Loken 2013, Heinze 2018)\n",
    "* what to do with many possible models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Likelihood ratio tests\n",
    "\n",
    "Stick with our example:\n",
    "$$\n",
    "\\begin{align}\n",
    "M_1: y_i &\\sim \\mathcal{N} \\left( \\alpha_0 + \\alpha_1 x_i , \\sigma_1^2 \\right) \\\\\n",
    "M_2: y_i &\\sim \\mathcal{N} \\left( \\beta_0 + \\beta_1 x_i + \\beta_2 t_i, \\sigma_2 ^2 \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "it is straightforward to calculate the likelihood of observed outcomes given each model: $p(y | x, M_1)$ and $p(y | x, M_1)$.\n",
    "Often "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References / read more\n",
    "\n",
    "* Gelman, A., & Loken, E. (2013, November 14). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no “fishing expedition” or “p-hacking” and the research hypothesis …. Retrieved from http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf\n",
    "* Heinze, G., Wallisch, C., & Dunkler, D. (2018). Variable selection – A review and recommendations for the practicing statistician. Biometrical Journal, 60(3), 431–449. https://doi.org/10.1002/bimj.201700067\n",
    "* Navarro, D. J. (2018). Between the Devil and the Deep Blue Sea: Tensions Between Scientific Judgement and Statistical Model Selection. Computational Brain & Behavior. https://doi.org/10.1007/s42113-018-0019-z\n",
    "* Piironen, J., & Vehtari, A. (2017). Comparison of Bayesian predictive methods for model selection. Statistics and Computing, 27(3), 711–735. https://doi.org/10.1007/s11222-016-9649-y\n",
    "* Vehtari, A., Gelman, A., & Gabry, J. (2017). Practical Bayesian Model Evaluation Using Leave-One-out Cross-Validation and WAIC. Statistics and Computing, 27(5), 1413–1432. https://doi.org/10.1007/s11222-016-9696-4\n",
    "* Yao, Y., Vehtari, A., Simpson, D., & Gelman, A. (2018). Using Stacking to Average Bayesian Predictive Distributions. Bayesian Analysis. https://doi.org/10.1214/17-BA1091\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
